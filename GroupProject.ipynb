{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st model attempt###\n",
    "First we import all the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functions import transforms as T \n",
    "from functions.subsample import MaskFunc\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = glob.glob('/tmp/NC2019MRI/train/*')\n",
    "MRI_scan_train= []\n",
    "MRI_scan = []\n",
    "for file in files:\n",
    "    with h5py.File(file,  \"r\") as hf:\n",
    "        volume_kspace = hf['kspace'][()]\n",
    "        MRI_scan.append(volume_kspace)\n",
    "        for MRI_slice in volume_kspace:\n",
    "            MRI_scan_train.append(MRI_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def show_slices(data, slice_nums, cmap=None): # visualisation\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    for i, num in enumerate(slice_nums):\n",
    "        plt.subplot(1, len(slice_nums), i + 1)\n",
    "        plt.imshow(data[num], cmap=cmap)\n",
    "        plt.axis('off')      \n",
    "    \n",
    "mask_MRI = MaskFunc(center_fractions=[0.08], accelerations=[4])  # Create the mask function object\n",
    "mask_MRI_8 = MaskFunc(center_fractions=[0.04], accelerations=[8])   \n",
    "\n",
    "\n",
    "def convert_to_image(MRI_scan,fold = False):\n",
    "    returned_list = []\n",
    "    if fold != False:\n",
    "        if fold == 4:\n",
    "            mask_MRI = MaskFunc(center_fractions=[0.08], accelerations=[4])\n",
    "        elif fold == 8:\n",
    "            mask_MRI = MaskFunc(center_fractions=[0.04], accelerations=[8])  \n",
    "            \n",
    "        for MRI in MRI_scan:\n",
    "            \n",
    "            MRI_tensor = T.to_tensor(MRI) \n",
    "            shape = np.array(MRI_tensor.shape)\n",
    "            mask = mask_MRI(shape, seed=0) # use seed here to exclude randomness  \n",
    "            masked_kspace = torch.where(mask == 0, torch.Tensor([0]), MRI_tensor) # masked kspace data with AF=4\n",
    "            \n",
    "            S_Num, Ny, Nx = MRI_tensor.shape\n",
    "            masks = mask.repeat(S_Num, Ny, 1, 1).squeeze() # masks when AF=4\n",
    "\n",
    "            volume_image = T.ifft2(masked_kspace)            # Apply Inverse Fourier Transform to get the complex image\n",
    "            volume_image_abs = T.complex_abs(volume_image)   # Compute absolute value to get a real image\n",
    "            returned_list.append(volume_image_abs)  \n",
    "        \n",
    "    else:\n",
    "        for MRI in MRI_scan:\n",
    "            MRI_tensor = T.to_tensor(MRI)      # Convert from numpy array to pytorch tensor\n",
    "            volume_image = T.ifft2(MRI_tensor)            # Apply Inverse Fourier Transform to get the complex image\n",
    "            volume_image_abs = T.complex_abs(volume_image)   # Compute absolute value to get a real image\n",
    "            returned_list.append(volume_image_abs)\n",
    "    return returned_list\n",
    "\n",
    "\n",
    "def crop_im(MRI_scan):\n",
    "    returned = []\n",
    "    for scan in MRI_scan:\n",
    "        scan = scan.clone()[160:480,24:344]\n",
    "        returned.append(scan)\n",
    "    return returned\n",
    "\n",
    "\n",
    "vol_im_full = convert_to_image(MRI_scan_train)\n",
    "print('1')\n",
    "vol_im_4 = convert_to_image(MRI_scan_train, 4)\n",
    "print('2')\n",
    "#vol_im_8 = convert_to_image(MRI_scan_train, 8)\n",
    "print('3')\n",
    "\n",
    "crop_full = crop_im(vol_im_full)\n",
    "crop_4 = crop_im(vol_im_4)\n",
    "#crop_8 = crop_im(vol_im_8)\n",
    "\n",
    "\n",
    "        \n",
    "#show_slices(crop_full, [5, 10, 20, 30], cmap='gray') # Original images without undersampling\n",
    "#show_slices(crop_4, [5, 10, 20, 30], cmap='gray') # Original images without undersampling\n",
    "#show_slices(crop_8, [5, 10, 20, 30], cmap='gray') # Original images without undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train_loader is used in order to group the data into batches.\n",
    "Here, I am assuming the train_set contains only the 4-fold and complete MRI scans. We don't need the 8-fold yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32) #can also try 64 or 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.device_count() #check number of GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just take one batch from the train_loader and check if the model is working using it. \n",
    "I also made a grid to visualise the images which hopefully will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "four_folds, full_scans = batch[0].to(device), batch[1].to(device)\n",
    "print(four_folds.shape)\n",
    "print(full_scans.shape)\n",
    "grid = torchvision.utils.make_grid(four_folds[:][0:7], nrow=2)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(np.transpose(grid, (1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the neural net architecture. The layers are the same as the original AlexNet. I have changed a lot of the hyperparameters inside the model the original values were tuned for 256x images and ours are 320x. \n",
    "\n",
    "I have also changed the number of neurons in the fully connected layers in order to get a 320x image as the output of the forward propagation. \n",
    "\n",
    "Finally, I have applied a sigmoid activation function on the last layer to make sure all values are between 0 and 1, then I multiplied that by 255 and changed the type to Int32. Essentially, I transformed all output values into pixel values. \n",
    "\n",
    "The numbers I have commented next to the layers are the lengths of the square matrix on that specific layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=102400):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=9, stride=5, padding=2), #64/64\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=4, stride=2),  #31/31\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2), #31/31\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), #15/15\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1), #15/15\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1), #15/15\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1), #15/15\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), #7/7\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 7 * 7, 32768),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(32768, 65536),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(65536, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        x = nn.functional.sigmoid(x)\n",
    "        x = x * 255\n",
    "        x = x.type(torch.int32)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set this to true before strating the backprop!!!! #\n",
    "\n",
    "As long as this is false, the gradients cannot be computed. It does make the forward prop a little bit faster so I set it to false initially.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False) #set to true before starting the training!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on how long the next step takes to compute, we can get a rough idea of how long we'd have to wait for the training process. If it takes a few seconds, then the training will probably take a few hours, so we might want to look again at the architecture and decide if we wanna change something first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = AlexNet()\n",
    "network.to(device) #move the model on the GPU\n",
    "#network = nn.DataParallel(network) #if we have access to more than 1 GPU\n",
    "output = network(four_folds)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for mean absolute error... couldn't find it already built in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(output, target):\n",
    "    loss = torch.mean(abs(output - target))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should, in theory, return the loss for all images in the batch combined. I flattened the full_scans. I'm pretty sure it won't work. I'll have to look at the shape of the data to change it properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = mae(output, torch.flatten(full_scans, 1))\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will compute the gradients after backprop and return the shape of the gradient tensor for the first layer, which should be the same as the shape of the weight tensor for that layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "network.features[0].weight.grad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will update all the weights based on the previously computed gradients. The algorithm I used for optimisation, Adam, basically makes sure the model will converge towards a minimum faster.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(network.parameters(), lr=0.03)\n",
    "optimizer.step() \n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything went well so far, we're gonna try going through the whole training set once.\n",
    "The total loss should hopefully decrease from one batch to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = []\n",
    "for batch in train_loader:\n",
    "    four_folds, full_scans = batch[0].to(device), batch[1].to(device)     #take the X and y out of the batch\n",
    "    full_scans = torch.flatten(full_scans, 1)    #flatten the full scans\n",
    "    output = network(four_folds)       #feedforward\n",
    "    loss = mae(output, full_scans)     #compute the loss\n",
    "    optimizer.zero_grad()       #set current gradients to 0\n",
    "    loss.backward()      #backpropagate\n",
    "    optimizer.step()     #update the weights\n",
    "    total_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If by some miracle we get all the way here in a reasonable amount of time, we can try running multiple epochs and seeing how low we can get the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        four_folds, full_scans = batch[0].to(device), batch[1].to(device)     #take the X and y out of the batch\n",
    "        full_scans = torch.flatten(full_scans, 1)    #flatten the full scans\n",
    "        output = network(four_folds)       #feedforward\n",
    "        loss = mae(output, full_scans)     #compute the loss\n",
    "        optimizer.zero_grad()       #set current gradients to 0\n",
    "        loss.backward()      #backpropagate\n",
    "        optimizer.step()     #update the weights\n",
    "        total_loss += loss.item()\n",
    "    print(total_loss, \"  \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
