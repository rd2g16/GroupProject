{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd model attempt###\n",
    "We import the same libraries as before, adding the last one for the hyperparameter tunnig. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import h5py\n",
    "import glob\n",
    "from functions import transforms as T \n",
    "from functions.subsample import MaskFunc\n",
    "#from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('crop_full.pkl','rb') as f:\n",
    "            crop_full = pickle.load(f)\n",
    "with open('crop_4.pkl','rb') as f:\n",
    "            crop_4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_slices(data, slice_nums, cmap=None): # visualisation\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    for i, num in enumerate(slice_nums):\n",
    "        plt.subplot(1, len(slice_nums), i + 1)\n",
    "        plt.imshow(data[num], cmap=cmap)\n",
    "        plt.axis('off')      \n",
    "    \n",
    "mask_MRI = MaskFunc(center_fractions=[0.08], accelerations=[4])  # Create the mask function object\n",
    "mask_MRI_8 = MaskFunc(center_fractions=[0.04], accelerations=[8])   \n",
    "\n",
    "\n",
    "def convert_to_image(MRI_scan,fold = False):\n",
    "    returned_list = []\n",
    "    if fold != False:\n",
    "        if fold == 4:\n",
    "            mask_MRI = MaskFunc(center_fractions=[0.08], accelerations=[4])\n",
    "        elif fold == 8:\n",
    "            mask_MRI = MaskFunc(center_fractions=[0.04], accelerations=[8])  \n",
    "            \n",
    "        for MRI in MRI_scan:\n",
    "            \n",
    "            MRI_tensor = T.to_tensor(MRI) \n",
    "            shape = np.array(MRI_tensor.shape)\n",
    "            mask = mask_MRI(shape, seed=0) # use seed here to exclude randomness  \n",
    "            masked_kspace = torch.where(mask == 0, torch.Tensor([0]), MRI_tensor) # masked kspace data with AF=4\n",
    "            \n",
    "            S_Num, Ny, Nx = MRI_tensor.shape\n",
    "            masks = mask.repeat(S_Num, Ny, 1, 1).squeeze() # masks when AF=4\n",
    "\n",
    "            volume_image = T.ifft2(masked_kspace)            # Apply Inverse Fourier Transform to get the complex image\n",
    "            volume_image_abs = T.complex_abs(volume_image)   # Compute absolute value to get a real image\n",
    "            returned_list.append(volume_image_abs)  \n",
    "        \n",
    "    else:\n",
    "        for MRI in MRI_scan:\n",
    "            MRI_tensor = T.to_tensor(MRI)      # Convert from numpy array to pytorch tensor\n",
    "            volume_image = T.ifft2(MRI_tensor)            # Apply Inverse Fourier Transform to get the complex image\n",
    "            volume_image_abs = T.complex_abs(volume_image)   # Compute absolute value to get a real image\n",
    "            returned_list.append(volume_image_abs)\n",
    "    return returned_list\n",
    "\n",
    "\n",
    "def crop_im(MRI_scan):\n",
    "    returned = []\n",
    "    for scan in MRI_scan:\n",
    "        scan = scan.clone()[160:480,24:344]\n",
    "        returned.append(scan)\n",
    "    return returned\n",
    "\n",
    "\n",
    "vol_im_full = convert_to_image(MRI_scan_train)\n",
    "print('1')\n",
    "vol_im_4 = convert_to_image(MRI_scan_train, 4)\n",
    "print('2')\n",
    "vol_im_8 = convert_to_image(MRI_scan_train, 8)\n",
    "print('3')\n",
    "\n",
    "crop_full = crop_im(vol_im_full)\n",
    "crop_4 = crop_im(vol_im_4)\n",
    "crop_8 = crop_im(vol_im_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(crop_4, crop_full, test_size=0.4, random_state=42)\n",
    "a = (X_train,y_train)\n",
    "\n",
    "\n",
    "a = [1, 2, 3]\n",
    "b = []\n",
    "i = -1\n",
    "pop_list = []\n",
    "for a in X_train:\n",
    "    i += 1\n",
    "    if a.shape == torch.Size([320, 296]):\n",
    "        #print(i)\n",
    "        pop_list.append(i)\n",
    "\n",
    "for i in pop_list[::-1]:\n",
    "    X_train.pop(i)\n",
    "    y_train.pop(i)\n",
    "  \n",
    "\n",
    "i = -1\n",
    "pop_list = []\n",
    "for a in X_test:\n",
    "    i += 1\n",
    "    if a.shape == torch.Size([320, 296]):\n",
    "        #print(i)\n",
    "        pop_list.append(i)\n",
    "        \n",
    "for i in pop_list[::-1]:\n",
    "    X_test.pop(i)\n",
    "    y_test.pop(i)\n",
    "    \n",
    "    \n",
    "X_train = torch.stack(X_train)    \n",
    "y_train = torch.stack(y_train)    \n",
    "train_set = torch.stack((X_train,y_train))\n",
    "train_set = train_set.unsqueeze(dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train_loader is used in order to group the data into batches.\n",
    "Here, I am assuming the train_set contains only the 4-fold and complete MRI scans. We don't need the 8-fold yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=2) #can also try 64 or 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.device_count() #check number of GPUs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just take one batch from the train_loader and check if the model is working using it. \n",
    "I also made a grid to visualise the images which hopefully will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1470, 1, 320, 320])\n",
      "torch.Size([1470, 1, 320, 320])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1470, 1, 320, 320])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tb = SummaryWriter()\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "four_folds, full_scans = batch[0].to(device), batch[1].to(device)\n",
    "print(four_folds.shape)\n",
    "print(full_scans.shape)\n",
    "#grid = torchvision.utils.make_grid(four_folds[:][0:7], nrow=2)\n",
    "\n",
    "#tb.add_image(\"images\", grid)\n",
    "\n",
    "#plt.figure(figsize=(15,15))\n",
    "#plt.imshow(np.transpose(grid, (1,2,0)))\n",
    "#plt.show()\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the neural net architecture. The layers are the same as the original AlexNet. I have changed a lot of the hyperparameters inside the model the original values were tuned for 256x images and ours are 320x. \n",
    "\n",
    "I have also changed the number of neurons in the fully connected layers in order to get a 320x image as the output of the forward propagation. \n",
    "\n",
    "Finally, I have applied a sigmoid activation function on the last layer to make sure all values are between 0 and 1, then I multiplied that by 255 and changed the type to Int32. Essentially, I transformed all output values into pixel values. \n",
    "\n",
    "The numbers I have commented next to the layers are the lengths of the square matrix on that specific layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=4), #320/320\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 192, kernel_size=9, padding=4), #320/320\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 384, kernel_size=7, padding=3), #320/320\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 192, kernel_size=5, padding=2), #320/320\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 64, kernel_size=3, padding=1), #320/320\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 1, kernel_size=3, padding=1),  # 320/320\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        #x = nn.functional.sigmoid(x)\n",
    "        #x = x * 255\n",
    "        #x = x.type(torch.int32)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set this to true before strating the backprop!!!! #\n",
    "\n",
    "As long as this is false, the gradients cannot be computed. It does make the forward prop a little bit faster so I set it to false initially.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x2488952e470>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False) #set to true before starting the training!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on how long the next step takes to compute, we can get a rough idea of how long we'd have to wait for the training process. If it takes a few seconds, then the training will probably take a few hours, so we might want to look again at the architecture and decide if we wanna change something first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 35.89 GiB (GPU 0; 6.00 GiB total capacity; 1.76 GiB already allocated; 2.37 GiB free; 508.12 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-5ba10fcb73d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#tb.close()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfour_folds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-130-ce4bf872448f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;31m#x = nn.functional.sigmoid(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m#x = x * 255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 35.89 GiB (GPU 0; 6.00 GiB total capacity; 1.76 GiB already allocated; 2.37 GiB free; 508.12 MiB cached)"
     ]
    }
   ],
   "source": [
    "network = AlexNet()\n",
    "network.to(device) #move the model on the GPU\n",
    "\n",
    "#tb.add_graph(network, four_folds)\n",
    "#tb.close()\n",
    "\n",
    "output = network(four_folds)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for mean absolute error... couldn't find it already built in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(output, target):\n",
    "    loss = torch.mean(abs(output - target))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should, in theory, return the loss for all images in the batch combined. I flattened the full_scans. I'm pretty sure it won't work. I'll have to look at the shape of the data to change it properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = mae(output, torch.flatten(full_scans, 1))\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will compute the gradients after backprop and return the shape of the gradient tensor for the first layer, which should be the same as the shape of the weight tensor for that layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "network.features[0].weight.grad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will update all the weights based on the previously computed gradients. The algorithm I used for optimisation, Adam, basically makes sure the model will converge towards a minimum faster.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(network.parameters(), lr=0.03)\n",
    "optimizer.step() \n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything went well so far, we're gonna try going through the whole training set once.\n",
    "The total loss should hopefully decrease from one batch to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    four_folds, full_scans = batch[0].to(device), batch[1].to(device)     #take the X and y out of the batch\n",
    "    output = network(four_folds)       #feedforward\n",
    "    loss = mae(output, full_scans)     #compute the loss\n",
    "    optimizer.zero_grad()       #set current gradients to 0\n",
    "    loss.backward()      #backpropagate\n",
    "    optimizer.step()     #update the weights\n",
    "    print('total loss: ', loss.item())\n",
    "    tb.add_scalar('Loss', loss.item(), batch)\n",
    "    tb.add_histogram('C1 Weights', network.features[0].weight, batch)\n",
    "    tb.add_histogram('C1 Bias', network.features[0].bias, batch)\n",
    "    tb.add_histogram('C1 Grad', network.features[0].weight.grad, batch)\n",
    "    \n",
    "    tb.add_histogram('C2 Weights', network.features[2].weight, batch)\n",
    "    tb.add_histogram('C2 Bias', network.features[2].bias, batch)\n",
    "    tb.add_histogram('C2 Grad', network.features[2].weight.grad, batch)\n",
    "    \n",
    "    tb.add_histogram('C3 Weights', network.features[4].weight, batch)\n",
    "    tb.add_histogram('C3 Bias', network.features[4].bias, batch)\n",
    "    tb.add_histogram('C3 Grad', network.features[4].weight.grad, batch)\n",
    "    \n",
    "    tb.add_histogram('C4 Weights', network.features[6].weight, batch)\n",
    "    tb.add_histogram('C4 Bias', network.features[6].bias, batch)\n",
    "    tb.add_histogram('C4 Grad', network.features[6].weight.grad, batch)\n",
    "    \n",
    "    tb.add_histogram('C5 Weights', network.features[8].weight, batch)\n",
    "    tb.add_histogram('C5 Bias', network.features[8].bias, batch)\n",
    "    tb.add_histogram('C5 Grad', network.features[8].weight.grad, batch)\n",
    "    \n",
    "    tb.add_histogram('C6 Weights', network.features[10].weight, batch)\n",
    "    tb.add_histogram('C6 Bias', network.features[10].bias, batch)\n",
    "    tb.add_histogram('C6 Grad', network.features[10].weight.grad, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If by some miracle we get all the way here in a reasonable amount of time, we can try running multiple epochs and seeing how low we can get the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8e7636ce8d6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mfour_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_scans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m#take the X and y out of the batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mfull_scans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_scans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m#flatten the full scans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size_list = [32, 64, 128, 256]\n",
    "lr_list = [0.003, 0.01, 0.03, 0.06, 0.1]\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for lr in lr_list:\n",
    "        network = AlexNet()\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "        optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "        comment = f'batch_size={batch_size} lr={lr}'\n",
    "        tb = SummaryWriter(comment=comment)\n",
    "        for batch in train_loader:\n",
    "            four_folds, full_scans = batch[0].to(device), batch[1].to(device)     #take the X and y out of the batch\n",
    "            output = network(four_folds)       #feedforward\n",
    "            loss = mse_loss(output, full_scans)\n",
    "            optimizer.zero_grad()       #set current gradients to 0\n",
    "            loss.backward()      #backpropagate\n",
    "            optimizer.step()     #update the weights\n",
    "            print(loss.item(), \"  \")\n",
    "            total_corect = get_num_correct(output, full_scans)\n",
    "            tb.add_scalar('Loss', loss.item(), batch)\n",
    "            tb.add_scalar('Accuracy', total_loss/batch_size, batch)\n",
    "            tb.add_histogram('C1 Weights', network.features[0].weight, batch)\n",
    "            tb.add_histogram('C1 Bias', network.features[0].bias, batch)\n",
    "            tb.add_histogram('C1 Grad', network.features[0].weight.grad, batch)\n",
    "\n",
    "            tb.add_histogram('C2 Weights', network.features[2].weight, batch)\n",
    "            tb.add_histogram('C2 Bias', network.features[2].bias, batch)\n",
    "            tb.add_histogram('C2 Grad', network.features[2].weight.grad, batch)\n",
    "\n",
    "            tb.add_histogram('C3 Weights', network.features[4].weight, batch)\n",
    "            tb.add_histogram('C3 Bias', network.features[4].bias, batch)\n",
    "            tb.add_histogram('C3 Grad', network.features[4].weight.grad, batch)\n",
    "\n",
    "            tb.add_histogram('C4 Weights', network.features[6].weight, batch)\n",
    "            tb.add_histogram('C4 Bias', network.features[6].bias, batch)\n",
    "            tb.add_histogram('C4 Grad', network.features[6].weight.grad, batch)\n",
    "\n",
    "            tb.add_histogram('C5 Weights', network.features[8].weight, batch)\n",
    "            tb.add_histogram('C5 Bias', network.features[8].bias, batch)\n",
    "            tb.add_histogram('C5 Grad', network.features[8].weight.grad, batch)\n",
    "\n",
    "            tb.add_histogram('C6 Weights', network.features[10].weight, batch)\n",
    "            tb.add_histogram('C6 Bias', network.features[10].bias, batch)\n",
    "            tb.add_histogram('C6 Grad', network.features[10].weight.grad, batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
